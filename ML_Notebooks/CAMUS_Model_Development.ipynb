{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNET Model for the CAMUS dataset using the MONAI platform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will explore the models that will do a segmentation of the left ventricle. Here I will use the CAMUS dataset with the ES and ED phases with their corresponding ground truth masks as my input and output for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -qU \"monai[ignite, nibabel, torchvision,tqdm]==0.6.0\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "!python -c \"import cv2\" || pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import medpy\n",
    "import PIL\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.6.0\n",
      "Numpy version: 1.24.1\n",
      "Pytorch version: 1.12.1+cu113\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 0ad9e73639e30f4f1af5a1f4a45da9cb09930179\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.5\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.13.1+cu113\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.64.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.4\n",
      "pandas version: 1.5.2\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from monai.config import print_config\n",
    "print_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the base directory where the data resides. \n",
    "If using Google Drive set here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DATA_DIRECTORY = /content/drive/MyDrive/LVEF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using a local drive, set directory below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATA_DIRECTORY=C:/Workspace/Practice/Python/PyTorch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%env DATA_DIRECTORY =  C:/Workspace/Practice/Python/PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Workspace\\Practice\\Python\\PyTorch\n"
     ]
    }
   ],
   "source": [
    "## if environment variable is not set , get a temp directory. \n",
    "directory = os.environ.get(\"DATA_DIRECTORY\")\n",
    "ROOT_DIR = Path(tempfile.mkdtemp()) if directory is None else Path(directory)\n",
    "print(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkPathExists(path):\n",
    "  if not os.path.exists(path):\n",
    "    print(f\"Cannot access path: {path}\")\n",
    "  else:\n",
    "    print (f\"Path {path} accessible\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and extract the CAMUS dataset. This step is not needed if the data was downloaded and unzipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter()\n",
    "from monai.utils import set_determinism\n",
    "set_determinism(seed=0)\n",
    "from monai.apps import download_and_extract, extractall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMUS_ORIGINAL_DATA_DIR = 'CAMUS/original_data/data'\n",
    "CAMUS_DATA_DIR = 'New_CAMUS_png/CAMUS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path C:\\Workspace\\Practice\\Python\\PyTorch\\New_CAMUS_png\\CAMUS accessible\n"
     ]
    }
   ],
   "source": [
    "# May not work on WIndows\n",
    "#resource = \"https://scholar.cu.edu.eg/Dataset_BUSI.zip\"\n",
    "compressed_file = ROOT_DIR.joinpath(\"CAMUS.zip\")\n",
    "DATA_DIR = ROOT_DIR.joinpath(CAMUS_DATA_DIR)\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    extractall(compressed_file, ROOT_DIR)\n",
    "checkPathExists(DATA_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize the file names used for training and testing into Python lists for easy access when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_DIR = DATA_DIR.joinpath('Training')\n",
    "TESTING_DATA_DIR = DATA_DIR.joinpath('Testing')\n",
    "TWO_CHANNEL = '2CH'\n",
    "FOUR_CHANNEL = '4CH'\n",
    "PHASE_NAMES = ['ED', 'ES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set the file list as\n",
    "#[ \n",
    "#   ED [(input_file, mask_file), (input_file, mask_file), ....]\n",
    "#   ES [(input_file, mask_file), (input_file, mask_file), ....]\n",
    "#]\n",
    "def data_directories(data_path, class_names, chamber_view):\n",
    "    num_phases = len(class_names)\n",
    "    patient_list = [x for x in data_path.iterdir() if x.is_dir()]\n",
    "\n",
    "    image_files_list = [\n",
    "        [\n",
    "            (p, Path(str(p).replace(f\"{class_names[i]}\", f\"{class_names[i]}_gt\")))\n",
    "            for x in patient_list\n",
    "            for j, p in enumerate(x.glob(f\"**/{chamber_view}*{class_names[i]}.png\"))\n",
    "        ]\n",
    "        for i in range(num_phases)\n",
    "    ]\n",
    "    return image_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_2chamber_image_files = data_directories(TRAINING_DATA_DIR, PHASE_NAMES, TWO_CHANNEL)\n",
    "training_4chamber_image_files = data_directories(TRAINING_DATA_DIR, PHASE_NAMES, FOUR_CHANNEL)\n",
    "testing_2chamber_image_files = data_directories(TESTING_DATA_DIR, PHASE_NAMES, TWO_CHANNEL)\n",
    "testing_4chamber_image_files = data_directories(TESTING_DATA_DIR, PHASE_NAMES, FOUR_CHANNEL)\n",
    "#pp.pprint(training_2chamber_image_files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_description(image_files_list):\n",
    "    num_total = len(image_files_list[0])\n",
    "    image_width, image_height = PIL.Image.open(image_files_list[0][0][0]).size\n",
    "    print(f\"Total Image Count: {num_total}\")\n",
    "    print(f\"Image Dimensions: {image_width} x {image_height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two Chamber Training Data Count\n",
      "Total Image Count: 400\n",
      "Image Dimensions: 256 x 256\n",
      "-------------\n",
      "Four Chamber Training Data Count\n",
      "Total Image Count: 400\n",
      "Image Dimensions: 256 x 256\n",
      "-------------\n",
      "Two Chamber Testing Data Count\n",
      "Total Image Count: 50\n",
      "Image Dimensions: 256 x 256\n",
      "-------------\n",
      "Four Chamber Testing Data Count\n",
      "Total Image Count: 50\n",
      "Image Dimensions: 256 x 256\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Two Chamber Training Data Count\")\n",
    "data_description(training_2chamber_image_files)\n",
    "print(\"-------------\")\n",
    "print(f\"Four Chamber Training Data Count\")\n",
    "data_description(training_4chamber_image_files)\n",
    "print(\"-------------\")\n",
    "print(f\"Two Chamber Testing Data Count\")\n",
    "data_description(testing_2chamber_image_files)\n",
    "print(\"-------------\")\n",
    "print(f\"Four Chamber Testing Data Count\")\n",
    "data_description(testing_4chamber_image_files)\n",
    "print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-arlbtak8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
